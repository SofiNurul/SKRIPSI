# -*- coding: utf-8 -*-
"""BAB4 NAIVE BAYES-SOFI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_HiqYeLEeA1OLneDmbw3vjCSf5M1OcZj
"""

import pandas as pd
import re
import string
import nltk
from tqdm import tqdm
from nltk.corpus import stopwords as nltk_stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from textblob import TextBlob
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score
import matplotlib.pyplot as plt
from wordcloud import WordCloud

"""mendownload resource nltk yang dibutuhkan"""

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')

"""Memuat data"""

df = pd.read_csv('data-ulasan-shopee.csv', encoding='MacRoman')

"""Daftar stopwords dari NLTK dan tambahan khusus Bahasa Indonesia"""

additional_stopwords = set(['gk', 'yg', 'nya', 'dan', 'dll', 'saja', 'juga', 'untuk', 'dengan', 'atau', 'tapi', 'karena', 'seperti', 'yang', 'saya', 'ga', 'malah', 'tidak', 'lagi', 'ini', 'di', 'kok', 'aja', 'gak', 'jadi', 'ya', 'dah', 'bisa', 'ada', 'bgt', 'banget','kak','ituu','grgr','jd','pengen','dgn','udah'])
stopwords = set(nltk_stopwords.words('indonesian')).union(additional_stopwords)

"""Inisialisasi Lemmatizer"""

lemmatizer = WordNetLemmatizer()

"""Fungsi untuk membersihkan teks"""

def clean_text(text):
    text = text.lower()  # Mengubah teks menjadi huruf kecil
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)  # Menghilangkan URL
    text = text.encode('ascii', 'ignore').decode('ascii')  # Menghilangkan emoji dan karakter non-ASCII
    text = text.translate(str.maketrans('', '', string.punctuation))  # Menghilangkan tanda baca
    text = re.sub(r'\d+', '', text)  # Menghilangkan angka
    words = word_tokenize(text)  # Tokenisasi kata
    cleaned_text = ' '.join([lemmatizer.lemmatize(word) for word in words if word not in stopwords])  # Lematisasi dan penghilangan stopwords
    return cleaned_text

"""Fungsi untuk menentukan sentimen"""

def get_sentiment(text):
    analysis = TextBlob(text)
    if analysis.sentiment.polarity > 0:
        return 'positive'
    elif analysis.sentiment.polarity < 0:
        return 'negative'
    else:
        return 'neutral'

"""Menerapkan fungsi pembersihan teks"""

df['cleaned_content'] = df['content'].apply(clean_text)

"""Menerapkan fungsi sentimen"""

df['sentiment'] = df['cleaned_content'].apply(get_sentiment)

"""Menampilkan distribusi sentimen"""

print(df['sentiment'].value_counts())

"""Memisahkan fitur dan label"""

X = df['cleaned_content']
y = df['sentiment']

"""Mengubah teks menjadi fitur numerik"""

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(X)

"""Memisahkan data latih dan data uji"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Melatih model Naive Bayes"""

model = MultinomialNB()
model.fit(X_train, y_train)

"""Memprediksi data uji"""

y_pred = model.predict(X_test)

"""Menampilkan hasil evaluasi"""

print(classification_report(y_test, y_pred))
print('Accuracy:', accuracy_score(y_test, y_pred))

"""Menggabungkan semua ulasan positif dan negatif"""

positive_text = ' '.join(df[df['sentiment'] == 'positive']['cleaned_content'])
negative_text = ' '.join(df[df['sentiment'] == 'negative']['cleaned_content'])

"""Bar chart untuk distribusi sentimen"""

sentiment_counts = df['sentiment'].value_counts()
plt.figure(figsize=(8, 6))
plt.bar(sentiment_counts.index, sentiment_counts.values, color=['blue', 'green', 'red'])
plt.xlabel('Sentimen')
plt.ylabel('Jumlah')
plt.title('Distribusi Sentimen')
plt.show()

"""Pie chart untuk distribusi proporsi sentimen"""

plt.figure(figsize=(8, 6))
plt.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140, colors=['blue', 'green', 'red'])
plt.axis('equal')  # Agar pie chart menjadi bulat
plt.title('Proporsi Sentimen')
plt.show()

"""Membuat wordcloud untuk ulasan positif"""

wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_positive, interpolation='bilinear')
plt.axis('off')
plt.title('Wordcloud for Positive Reviews')
plt.show()

"""Membuat wordcloud untuk ulasan negatif"""

wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(negative_text)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud_negative, interpolation='bilinear')
plt.axis('off')
plt.title('Wordcloud for Negative Reviews')
plt.show()

"""Menyimpan data ke dalam file CSV dengan label sentimen"""

df.to_csv('sentiment_ulasan_shopee.csv', index=False)

"""data dengan sentimen positif"""

print("Contoh data dengan sentimen positif:")
print(df[df['sentiment'] == 'positive'][['content', 'cleaned_content', 'sentiment']].head(15))
print("\n")

"""data dengan sentimen negatif"""

print("Contoh data dengan sentimen negatif:")
print(df[df['sentiment'] == 'negative'][['content', 'cleaned_content', 'sentiment']].head(15))
print("\n")

"""data dengan sentimen netral"""

print("Contoh data dengan sentimen netral:")
print(df[df['sentiment'] == 'neutral'][['content', 'cleaned_content', 'sentiment']].head(15))
print("\n")